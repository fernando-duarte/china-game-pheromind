# China Economic Data Analysis

This package contains scripts to download, process, and analyze economic data for China from multiple sources including the World Bank, Penn World Table, and IMF Fiscal Monitor. It provides tools for data retrieval, processing, analysis, and projection of economic indicators.

## Setup and Installation

### Prerequisites

- Python 3.7 or higher (Python 3.13+ recommended)
  - The script will work with either the `python3` or `python` command, as long as it's Python 3
- Internet connection (for downloading data)
- pip package manager

### Installation

1. Open Terminal
2. Navigate to the `china_data` directory
3. Run the setup script:
   ```bash
   ./setup.sh
   ```

The setup script will:
- Create a Python virtual environment (if not already in one)
- Install all required dependencies
- Run the data downloader and processor scripts
- Store output files in the `output` directory

> **Note:** The setup script can be run from inside an existing virtual environment or from outside. If run from inside an existing virtual environment, it will use that environment instead of creating a new one.

### Dependencies

The package relies on several Python libraries:
- pandas: Data manipulation and analysis
- pandas-datareader: Interface for extracting data from various web sources
- numpy: Numerical computing
- scikit-learn: Machine learning and statistical modeling
- statsmodels: Statistical models and tests
- matplotlib: Data visualization (for development)
- pytest: Testing framework (for development)

### Setup Script Options

The setup script supports several command-line options:

```bash
./setup.sh --help
```

Options include:
- `--dev`: Install development dependencies and run tests after data scripts.
  
- `--test`: Install development dependencies and run tests only (skips data scripts).
  
- `-a=VALUE, --alpha=VALUE`: Capital share parameter for TFP calculation (default: 0.33).
  - This corresponds to the α parameter in the Cobb-Douglas production function.
  
- `-k=VALUE, --capital-output-ratio=VALUE`: Capital-to-output ratio for base year 2017 (default: 3.0)..
  - For China, values between 2.5 and 3.5 are common in the literature.
  
- `-o=NAME, --output-file=NAME`: Base name for output files (default: china_data_processed).
  - Generated files will use this base name with extensions .md, .csv.
  
- `--end-year=YYYY`: Last year to process/download data for (default: 2025, ignored if `--test` is used).
  - Code uses extrapolation methods to project data to the specified end year if actual data is not available.

Example:
```bash
./setup.sh -a=0.4 -k=2.5 -o=custom_output --end-year=2030
```

## Manual Setup

If you prefer to set up manually:

1. Create a virtual environment:
   ```bash
   python -m venv venv
   ```

   or

   ```bash
   python3 -m venv venv
   ```

2. Activate the virtual environment:
   - On macOS/Linux:
     ```bash
     source venv/bin/activate
     ```
   - On Windows:
     ```
     venv\Scripts\activate
     ```

3. Upgrade pip:
   ```bash
   pip install --upgrade pip
   ```

4. Install setuptools with distutils support:
   ```bash
   pip install setuptools>=67.0.0  # Required for pandas-datareader compatibility with Python 3.13+
   ```

5. Install dependencies (choose one option):

   For basic usage:
   ```bash
   pip install -r requirements.txt
   ```

   For development (includes testing tools):
   ```bash
   pip install -r dev-requirements.txt
   ```

6. Run the scripts:
   ```bash
   python china_data_downloader.py
   python china_data_processor.py
   ```

## Running Tests

There are several ways to run the automated tests:

### Using the Setup Script

1.  **Run tests as part of development setup**:
    This command will install development dependencies, run the data downloader and processor, and then execute the tests.
    ```bash
    ./setup.sh --dev
    ```

2.  **Run tests only**:
    This command will install development dependencies and then execute the tests, skipping the data downloader and processor scripts.
    ```bash
    ./setup.sh --test
    ```

### Manual Test Execution

If you prefer to run tests manually:

1.  Ensure you have activated the virtual environment:
    ```bash
    source venv/bin/activate
    ```
2.  Ensure development dependencies are installed:
    ```bash
    pip install -r dev-requirements.txt
    ```
3.  Navigate to the `china_data` directory (if not already there).
4.  Run pytest:
    ```bash
    python -m pytest
    ```
    Or simply:
    ```bash
    pytest
    ```
    Pytest will automatically discover and run tests in the `tests/` subdirectory.

## Output Files

All output files are stored in the `output` directory after running the scripts:

- `china_data_raw.md`: Raw data in markdown format (generated by downloader)
  - Contains original data from World Bank WDI, IMF Fiscal Monitor, and Penn World Table
  - Includes source attribution and data descriptions
  - Records download dates

- `china_data_processed.md`: Processed data in markdown format (generated by processor)
  - Contains transformed and calculated economic variables
  - Includes detailed documentation on calculation methods
  - Specifies which years are extrapolated for each variable, and methods used

- `china_data_processed.csv`: Processed data in CSV format (generated by processor)
  - Contains the same data as the data table in the markdown file with the same name
  - Useful for importing into other analysis tools

## Data Sources

The package retrieves and processes data from the following sources:

- **International Monetary Fund (IMF) Fiscal Monitor**
  - Tax revenue data (replaces World Bank tax revenue data)
    - G1_S13_POGDP_PT: Tax revenue as percentage of GDP
  - Includes both historical data and official IMF projections through 2030
  - The IMF data is pre-downloaded and stored in the input directory

- **World Bank World Development Indicators (WDI)**
  - GDP and its components (consumption, government, investment, exports, imports)
    - NY.GDP.MKTP.CD: GDP (current US$)
    - NE.CON.PRVT.CD: Household consumption (current US$)
    - NE.CON.GOVT.CD: Government consumption (current US$)
    - NE.GDI.TOTL.CD: Gross capital formation (current US$)
    - NE.EXP.GNFS.CD: Exports (current US$)
    - NE.IMP.GNFS.CD: Imports (current US$)
  - Foreign Direct Investment (FDI)
    - BX.KLT.DINV.WD.GD.ZS: Foreign direct investment as percentage of GDP
  - Population and labor force data
    - SP.POP.TOTL: Population, total
    - SL.TLF.TOTL.IN: Labor force, total
  - Downloaded dynamically using pandas-datareader

- **Penn World Table (PWT) version 10.01**
  - Real GDP (rgdpo)
  - Capital stock (rkna)
  - Price level (pl_gdpo)
  - Nominal GDP (cgdpo)
  - Human capital index (hc)
  - Downloaded programmatically during execution

## Data Processing Pipeline

The data processing pipeline consists of several stages:

1. **Data Download**: Retrieves data from multiple sources and merges them into a single dataset
2. **Unit Conversion**: Converts various units to standardized formats (billions USD, millions people)
3. **Capital Stock Calculation**: Calculates capital stock using investment data and capital-output ratio
4. **Projections**: Projects key variables (capital stock, human capital) to future years
5. **Data Extrapolation**: Extends base time series to end year using appropriate statistical methods
6. **Economic Indicators**: Calculates derived indicators like:
   - Total Factor Productivity (TFP)
   - Net exports
   - Capital-output ratio
   - Tax revenue
   - Openness ratio (trade as % of GDP)
   - Total, private, and public savings
   - Saving rate
7. **Output Generation**: Formats results and generates output files

> **Note:** Extrapolation is performed before calculating economic indicators so that derived indicators can be calculated from already-extrapolated base variables. This approach ensures consistency in the projected data and eliminates the need to separately extrapolate derived economic indicators.

## Economic Model

The package implements an open-economy growth model for China, documented in `china_growth_model.md`. Key components include:

- **Production Function**: Cobb-Douglas production function with TFP, physical capital, and human capital
- **Capital Accumulation**: Investment-based capital stock evolution
- **TFP Growth**: Base growth rate with spillover effects from trade openness and FDI
- **Trade Equations**: Models for exports and imports with exchange rate and income elasticities
- **Saving-Investment Balance**: National accounting identities with saving and investment

The economic indicators calculated by the processor align with this theoretical framework.

## Usage Examples

### Basic Data Processing

To download the latest data and process it with default parameters:

```bash
./setup.sh
```

This will create a complete dataset with projections using default parameters (α=0.33, capital-output ratio=3.0).

### Custom Parameter Analysis

To analyze the data with different economic assumptions:

```bash
./setup.sh -a=0.4 -k=3.5 --end-year=2030
```

This allows testing different theoretical assumptions about China's economy:
- Higher capital share (α=0.4) suggests capital contributes more to output growth
- Different capital-output ratio affects capital stock calculations
- Extended projection to 2030 provides longer-term forecasts

### Generating Data for Further Analysis

To produce data files for use in other analytical tools:

```bash
python china_data_downloader.py
python china_data_processor.py -o china_data_for_analysis
```

The resulting CSV file can be imported into statistical software, spreadsheets, or visualization tools for:
- Time series analysis
- Growth accounting
- Cross-country comparisons
- Custom visualizations

### Updating with New Data

When new data becomes available:

```bash
./setup.sh --dev
```

This will:
1. Download the latest available data from all sources
2. Process the updated dataset
3. Run tests to ensure calculations remain valid
4. Output updated files with the most recent projections

<!-- Advanced Topics section commented out
## Advanced Topics

### Economic Model Details

The package implements a Solow-Swan growth model with a Cobb-Douglas production function:

$$Y_t = A_t \cdot K_t^\alpha \cdot (L_t \cdot h_t)^{1-\alpha}$$

Where:
- $Y_t$ is output (GDP)
- $A_t$ is Total Factor Productivity (TFP)
- $K_t$ is physical capital stock
- $L_t$ is labor input (typically employment)
- $h_t$ is human capital per worker
- $\alpha$ is the capital share parameter

#### Capital Stock Construction

The capital stock series is constructed using the perpetual inventory method (PIM):

$$K_t = (1-\delta) \cdot K_{t-1} + I_t$$

Where:
- $K_t$ is the capital stock at time $t$
- $\delta$ is the depreciation rate (default: 0.05 or 5% annually)
- $I_t$ is gross fixed capital formation (investment)

The initial capital stock $K_0$ is calculated using the specified capital-output ratio:

$$K_0 = k \cdot Y_0$$

Where $k$ is the capital-output ratio parameter (default: 3.0).

#### Total Factor Productivity Calculation

TFP is calculated as the residual from the production function:

$$A_t = \frac{Y_t}{K_t^\alpha \cdot (L_t \cdot h_t)^{1-\alpha}}$$

TFP growth is a key driver of long-term economic growth in the model and is projected using time series methods (ARIMA by default).

#### Human Capital Construction

Human capital per worker is modeled as a function of average years of schooling:

$$h_t = e^{\phi(s_t)}$$

Where:
- $s_t$ is the average years of schooling
- $\phi(s)$ is a piecewise linear function with different returns to education at different levels

For details on the complete economic model, refer to `china_growth_model.md`.

### Custom Data Sources

You can add custom data sources by:

1. Creating a new source handler in `utils/data_sources.py`
   - Implement a class that extends the `DataSource` base class
   - Override the `fetch_data()` method to retrieve data from your source
   - Implement any necessary data cleaning and formatting

2. Registering it in the downloader script:
   ```python
   # In china_data_downloader.py
   from utils.data_sources import YourCustomSource
   
   # Initialize your source
   custom_source = YourCustomSource(params)
   
   # Add it to the pipeline
   sources.append(custom_source)
   ```

3. Adding appropriate processing logic in the processor script:
   ```python
   # In china_data_processor.py
   # Add processing for your custom data
   custom_data = data['your_custom_source']
   processed_data = process_custom_data(custom_data)
   ```

### Extending Projections

The package uses multiple projection methods:

1. **ARIMA Time Series Models**: Used for TFP and other key variables
   - Implemented in `utils/projections.py` with `arima_forecast()`
   - Automatically selects optimal parameters (p,d,q) using AIC
   - Example modification to change to BIC criterion:
     ```python
     def arima_forecast(series, periods=5, information_criterion='bic'):
         # Modified implementation using BIC instead of AIC
     ```

2. **Growth Rate Extrapolation**: Used for simpler variables
   - Implemented with `growth_rate_forecast()`
   - Uses average growth rates from historical data
   - Example to modify the lookback period:
     ```python
     def growth_rate_forecast(series, periods=5, lookback_years=10):
         # Use the most recent 10 years for growth rate calculation
     ```

3. **Structural Models**: Used for demographics and other variables with known patterns
   - Can be extended by implementing domain-specific models
   - Example for demographic projection:
     ```python
     def demographic_forecast(population_data, fertility_rates, mortality_rates):
         # Implement cohort component model
     ```

To add a new projection method:

1. Implement the method in `utils/projections.py`
2. Modify the processor script to use your method for appropriate variables:
   ```python
   # In china_data_processor.py
   from utils.projections import your_new_forecast_method
   
   # Use for appropriate variable
   projected_values = your_new_forecast_method(historical_data)
   ```

### Common Issues and Solutions

#### Missing Data

If certain years have missing data:
- The processor attempts to fill gaps using appropriate statistical methods:
  ```python
  # Example from processor_extrapolation.py
  def fill_gaps(series):
      # Linear interpolation for small gaps
      series_filled = series.interpolate(method='linear')
      # Return interpolated series
      return series_filled
  ```
- Check the extrapolation section in the processed markdown file for details on which methods were used
- For systematic gaps in specific variables, consider:
  - Modifying the interpolation method in `utils/processor_extrapolation.py`
  - Adding alternative data sources that might have better coverage
  - Using more sophisticated gap-filling techniques like KNN or regression

#### API Limitations

If you encounter API rate limits:
- The downloader includes automatic retry mechanisms with exponential backoff:
  ```python
  # Example from wdi_downloader.py
  def download_with_retries(indicator, country, max_retries=5):
      for attempt in range(max_retries):
          try:
              # Download data
              return data
          except Exception as e:
              wait_time = 2 ** attempt  # Exponential backoff
              time.sleep(wait_time)
      raise Exception(f"Failed to download after {max_retries} attempts")
  ```
- You can manually re-run the downloader script if needed
- Consider using cached data with the `--use-cached` option:
  ```bash
  python china_data_downloader.py --use-cached
  ```
- If working with large batches, spread requests over time by using the `--delay` option:
  ```bash
  python china_data_downloader.py --delay=2
  ```

#### Computational Performance

For large datasets or extended projections:
- Enable multiprocessing for parallel computation:
  ```python
  # Example usage in processor script
  from utils.processor_parallel import process_in_parallel
  
  # Process data in parallel
  results = process_in_parallel(data, num_processes=4)
  ```
- Optimize memory usage by processing data in chunks:
  ```python
  # Example chunked processing
  chunk_size = 1000
  for i in range(0, len(data), chunk_size):
      chunk = data[i:i+chunk_size]
      process_chunk(chunk)
  ```
- For extremely large datasets, consider:
  - Using dask for out-of-memory computation
  - Implementing selective processing with the `--variables` option:
    ```bash
    python china_data_processor.py --variables=gdp,investment,tfp
    ```
  - Using the `--start-year` and `--end-year` options to limit the time range

#### Projection Accuracy

To improve the accuracy of economic projections:
- Evaluate multiple projection methods using historical data:
  ```python
  from utils.projection_evaluation import evaluate_methods
  
  # Test accuracy of different methods
  best_method = evaluate_methods(historical_data, methods=['arima', 'linear', 'growth_rate'])
  ```
- Adjust parameters based on domain knowledge:
  ```bash
  python china_data_processor.py --alpha=0.4 --capital-output-ratio=2.8 --depreciation-rate=0.06
  ```
- For research purposes, generate sensitivity analysis by running multiple projections:
  ```bash
  for alpha in 0.3 0.35 0.4 0.45 0.5; do
    python china_data_processor.py --alpha=$alpha --output-file=sensitivity_alpha_$alpha
  done
  ```
- Consider external factors that might affect future projections (policy changes, demographic shifts) and adjust models accordingly
-->

## License

This project is for educational purposes only. The code and documentation are provided "as is" without warranty of any kind, express or implied. Users are free to:

- Use the code for academic and research purposes
- Modify and distribute the code, provided proper attribution is given
- Contribute improvements via pull requests

When using this software for academic work, please cite:

```
Duarte, Fernando. China Economic Data Analysis Package (2025).
GitHub: https://github.com/econ-research/china-data-analysis
```

### Data Source Licensing

This package retrieves and processes data from various sources, each with their own terms of use:

- **World Bank WDI**: Data is available under the [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/)
- **Penn World Table**: Academic use permitted with proper citation of [Feenstra, Robert C., Robert Inklaar and Marcel P. Timmer (2015)](https://www.rug.nl/ggdc/productivity/pwt/)
- **IMF Fiscal Monitor**: Data used according to the [IMF Terms and Conditions](https://www.imf.org/external/terms.htm)

Users should ensure they comply with the terms of use for each data source.
